{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Shakespeare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['austen-emma.txt',\n",
       " 'austen-persuasion.txt',\n",
       " 'austen-sense.txt',\n",
       " 'bible-kjv.txt',\n",
       " 'blake-poems.txt',\n",
       " 'bryant-stories.txt',\n",
       " 'burgess-busterbrown.txt',\n",
       " 'carroll-alice.txt',\n",
       " 'chesterton-ball.txt',\n",
       " 'chesterton-brown.txt',\n",
       " 'chesterton-thursday.txt',\n",
       " 'edgeworth-parents.txt',\n",
       " 'melville-moby_dick.txt',\n",
       " 'milton-paradise.txt',\n",
       " 'shakespeare-caesar.txt',\n",
       " 'shakespeare-hamlet.txt',\n",
       " 'shakespeare-macbeth.txt',\n",
       " 'whitman-leaves.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shakespeare-caesar.txt\n",
      "shakespeare-hamlet.txt\n",
      "shakespeare-macbeth.txt\n"
     ]
    }
   ],
   "source": [
    "shakespeare_text = ''\n",
    "for filename in gutenberg.fileids():\n",
    "    if 'shakespeare' in filename.lower():\n",
    "        print(filename)\n",
    "        shakespeare_text += gutenberg.raw(filename).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = sorted(list(set(shakespeare_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_mapping = {char:index for index, char in enumerate(characters)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '&': 3,\n",
       " \"'\": 4,\n",
       " '(': 5,\n",
       " ')': 6,\n",
       " ',': 7,\n",
       " '-': 8,\n",
       " '.': 9,\n",
       " '0': 10,\n",
       " '1': 11,\n",
       " '2': 12,\n",
       " '3': 13,\n",
       " '4': 14,\n",
       " '5': 15,\n",
       " '6': 16,\n",
       " '9': 17,\n",
       " ':': 18,\n",
       " ';': 19,\n",
       " '?': 20,\n",
       " '[': 21,\n",
       " ']': 22,\n",
       " 'a': 23,\n",
       " 'b': 24,\n",
       " 'c': 25,\n",
       " 'd': 26,\n",
       " 'e': 27,\n",
       " 'f': 28,\n",
       " 'g': 29,\n",
       " 'h': 30,\n",
       " 'i': 31,\n",
       " 'j': 32,\n",
       " 'k': 33,\n",
       " 'l': 34,\n",
       " 'm': 35,\n",
       " 'n': 36,\n",
       " 'o': 37,\n",
       " 'p': 38,\n",
       " 'q': 39,\n",
       " 'r': 40,\n",
       " 's': 41,\n",
       " 't': 42,\n",
       " 'u': 43,\n",
       " 'v': 44,\n",
       " 'w': 45,\n",
       " 'x': 46,\n",
       " 'y': 47,\n",
       " 'z': 48,\n",
       " 'Ã¦': 49}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus of length 375542 consisting of 50 different characters\n"
     ]
    }
   ],
   "source": [
    "print(f'corpus of length {len(shakespeare_text)} consisting of {len(char_mapping)} different characters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[the tragedie of julius caesar by william shakespeare 1599]\n",
      "\n",
      "\n",
      "actus primus. scoena prima.\n",
      "\n",
      "enter flauius, murellus, and certaine commoners ouer the stage.\n",
      "\n",
      "  flauius. hence: home you idle creatures, get you home:\n",
      "is this a holiday? what, know you not\n",
      "(being mechanicall) you ought not walke\n",
      "vpon a labouring day, without the signe\n",
      "of your profession? speake, what trade art thou?\n",
      "  car. why sir, a carpenter\n",
      "\n",
      "   mur. where is thy leather apron, and thy rule?\n",
      "what dost thou with thy best apparrell on?\n",
      "you sir, what trade are you?\n",
      "  cobl. truely sir, in respect of a fine workman, i am\n",
      "but as you would say, a cobler\n",
      "\n",
      "   mur. but what trade art thou? answer me directly\n",
      "\n",
      "   cob. a trade sir, that i hope i may vse, with a safe\n",
      "conscience, which is indeed sir, a mender of bad soules\n",
      "\n",
      "   fla. what trade thou knaue? thou naughty knaue,\n",
      "what trade?\n",
      "  cobl. nay i beseech you sir, be not out with me: yet\n",
      "if you be out sir, i can mend you\n",
      "\n",
      "   mur. what mean'st thou by that? mend mee, thou\n",
      "sawcy fellow?\n"
     ]
    }
   ],
   "source": [
    "print(shakespeare_text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_length = 40\n",
    "step_size = 3\n",
    "ngrams = [i for i in range(0, len(shakespeare_text)-ngram_length, step_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'omnes.\\n\\n\\nfinis. the tragedie of macbeth.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shakespeare_text[ngrams[-1]:ngrams[-1] + ngram_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ngrams = [shakespeare_text[i:i+ngram_length] for i in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[the tragedie of julius caesar by willia'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ngrams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e tragedie of julius caesar by william s'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ngrams[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [shakespeare_text[i+ngram_length] for i in ngrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[the tragedie of julius caesar by willia'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ngrams[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125168"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(targets), ngram_length, len(char_mapping)))\n",
    "y = np.zeros((len(targets), len(char_mapping)))\n",
    "for i, text_ngram in enumerate(text_ngrams):\n",
    "    for j, token in enumerate(text_ngram):\n",
    "        x[i, j, char_mapping[token]] = 1\n",
    "for i, target in enumerate(targets):\n",
    "    y[i, char_mapping[target]] = 1\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "> ## If you've already trained a model and saved it, you can skip to \"Load Model\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(256, input_shape=(ngram_length, len(char_mapping))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(len(char_mapping)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile & save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=.01) # Seriously, ADAM's NOT the only game in town!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_structure = model.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lstm_shakespeare_model.json', 'w') as json_file:\n",
    "    json_file.write(model_structure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fit with intermittent saving\n",
    ">Obviously, I could have used Keras's ModelCheckpoint, but sometimes it's good to get your hands dirty ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "125168/125168 [==============================] - 120s 956us/step - loss: 2.0817 - accuracy: 0.3900\n",
      "Epoch 2/6\n",
      "125168/125168 [==============================] - 123s 984us/step - loss: 1.6347 - accuracy: 0.5043\n",
      "Epoch 3/6\n",
      "125168/125168 [==============================] - 124s 988us/step - loss: 1.5107 - accuracy: 0.5373\n",
      "Epoch 4/6\n",
      "125168/125168 [==============================] - 127s 1ms/step - loss: 1.4347 - accuracy: 0.5578\n",
      "Epoch 5/6\n",
      "125168/125168 [==============================] - 131s 1ms/step - loss: 1.3798 - accuracy: 0.5731\n",
      "Epoch 6/6\n",
      "125168/125168 [==============================] - 130s 1ms/step - loss: 1.3334 - accuracy: 0.5850\n",
      "Epoch 1/6\n",
      "125168/125168 [==============================] - 151s 1ms/step - loss: 1.2977 - accuracy: 0.5965\n",
      "Epoch 2/6\n",
      "125168/125168 [==============================] - 150s 1ms/step - loss: 1.2694 - accuracy: 0.6024\n",
      "Epoch 3/6\n",
      "125168/125168 [==============================] - 127s 1ms/step - loss: 1.2383 - accuracy: 0.6116\n",
      "Epoch 4/6\n",
      "125168/125168 [==============================] - 146s 1ms/step - loss: 1.2216 - accuracy: 0.6158\n",
      "Epoch 5/6\n",
      "125168/125168 [==============================] - 146s 1ms/step - loss: 1.2001 - accuracy: 0.6226\n",
      "Epoch 6/6\n",
      "125168/125168 [==============================] - 125s 1ms/step - loss: 1.1773 - accuracy: 0.6278\n",
      "Epoch 1/6\n",
      "125168/125168 [==============================] - 126s 1ms/step - loss: 1.1693 - accuracy: 0.6300\n",
      "Epoch 2/6\n",
      "125168/125168 [==============================] - 128s 1ms/step - loss: 1.1502 - accuracy: 0.6369\n",
      "Epoch 3/6\n",
      "125168/125168 [==============================] - 127s 1ms/step - loss: 1.1360 - accuracy: 0.6415\n",
      "Epoch 4/6\n",
      "125168/125168 [==============================] - 128s 1ms/step - loss: 1.1214 - accuracy: 0.6433\n",
      "Epoch 5/6\n",
      "125168/125168 [==============================] - 128s 1ms/step - loss: 1.1051 - accuracy: 0.6490\n",
      "Epoch 6/6\n",
      "125168/125168 [==============================] - 129s 1ms/step - loss: 1.0934 - accuracy: 0.6523\n",
      "Epoch 1/6\n",
      "125168/125168 [==============================] - 128s 1ms/step - loss: 1.0790 - accuracy: 0.6573\n",
      "Epoch 2/6\n",
      "125168/125168 [==============================] - 128s 1ms/step - loss: 1.0650 - accuracy: 0.6602\n",
      "Epoch 3/6\n",
      "125168/125168 [==============================] - 129s 1ms/step - loss: 1.0510 - accuracy: 0.6654\n",
      "Epoch 4/6\n",
      "125168/125168 [==============================] - 127s 1ms/step - loss: 1.0418 - accuracy: 0.6681\n",
      "Epoch 5/6\n",
      "125168/125168 [==============================] - 128s 1ms/step - loss: 1.0303 - accuracy: 0.6717\n",
      "Epoch 6/6\n",
      "125168/125168 [==============================] - 129s 1ms/step - loss: 1.0221 - accuracy: 0.6747\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model.fit(x=x, y=y, epochs=epochs, batch_size=batch_size)\n",
    "    model.save_weights(f'shakespeare_model_weights_{i+1}.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4th run-through seems to have given the best result, so we'll load that one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "with open(\"lstm_shakespeare_model.json\", \"r\") as json_file:\n",
    "    json_string = json_file.read()\n",
    "model = model_from_json(json_string)\n",
    "model.load_weights('shakespeare_model_weights_4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a new paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sentence(sentence, character_map):\n",
    "    \"\"\"convert sentence into one-hot encoding,\n",
    "    according to the character mapping\"\"\"\n",
    "    x = np.zeros((1, len(sentence), len(character_map)))\n",
    "    for i, s in enumerate(sentence):\n",
    "        x[0, i, character_map[s]] = 1\n",
    "    return x\n",
    "\n",
    "def generate_next_token(prediction, character_map, temperature=1):\n",
    "    \"\"\"receives prediction probabilities, \n",
    "    reduces or increases differences according to temperature,\n",
    "    samples from resulting distribution,\n",
    "    returns the index of the 1 in the one-hot vector \n",
    "    \"\"\"\n",
    "    reverse_character_map = {value:key for key, value in character_map.items()}\n",
    "    prediction = np.asarray(prediction).astype('float64')\n",
    "    prediction = np.log(prediction+.0001)/temperature\n",
    "    exponential_prediction = np.exp(prediction)\n",
    "    exponential_prediction /= exponential_prediction.sum()\n",
    "    sample = np.random.multinomial(1, exponential_prediction, 1)\n",
    "    return reverse_character_map[np.argmax(sample)]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initiating the seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random_start = random.randint(0, len(shakespeare_text) - ngram_length - 1)\n",
    "seed_sentence = shakespeare_text[random_start:random_start+ngram_length]\n",
    "sentence = seed_sentence\n",
    "text = seed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0.5  # the hotter it gets, the more the text will diverge from the learned probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(400):\n",
    "    sentence = text[-ngram_length:]\n",
    "    prediction = model.predict(convert_sentence(sentence, char_mapping))\n",
    "    next_token = generate_next_token(prediction[0], char_mapping, temperature)\n",
    "    text += next_token\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who was in life, a foolish prating knaue\n",
      "hath haue conclaticke with vssires, so it\n",
      "\n",
      "   cass. therefore the remember polona men sayes:\n",
      "and which haue he hath nature in his haile\n",
      "in the pleasets statuers of the conspiratie?\n",
      "  hor. no me. if it selfe cries the moone\n",
      "\n",
      "   3. there's brutus is conspirite,\n",
      "be not her deed, a brutus is the lites head:\n",
      "the trifited the grepose of the cloueds and gentlemen\n",
      "whose light in my fease enot sole of way\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
